# Training Configuration for Hybrid Vision Transformer Speech Enhancement

training:
  # Experiment Settings
  experiment_name: "hybrid_vit_speech_enhancement"
  seed: 42
  device: "cuda"  # "cuda" or "cpu"
  num_workers: 4
  pin_memory: true

  # Training Hyperparameters
  batch_size: 16
  num_epochs: 100
  gradient_clip_max_norm: 1.0
  gradient_accumulation_steps: 1

  # Mixed Precision Training
  use_amp: true  # Automatic Mixed Precision (FP16)

  # Optimizer Configuration
  optimizer:
    name: "adamw"  # "adam", "adamw", "sgd"
    lr: 0.0001  # Learning rate
    betas: [0.9, 0.999]
    eps: 1.0e-8
    weight_decay: 0.01
    amsgrad: false

  # Learning Rate Scheduler
  scheduler:
    name: "cosine"  # "cosine", "step", "plateau", "warmup_cosine"
    warmup_epochs: 5
    min_lr: 1.0e-6

    # For step scheduler
    step_size: 30
    gamma: 0.1

    # For plateau scheduler
    patience: 5
    factor: 0.5

  # Loss Configuration
  loss:
    # Loss weights
    l1_weight: 1.0
    mse_weight: 0.0
    stoi_weight: 0.1
    perceptual_weight: 0.0

    # Loss-specific parameters
    use_log_compression: false  # Apply log compression to spectrograms

  # Early Stopping
  early_stopping:
    enabled: true
    patience: 10
    min_delta: 0.0001

  # Checkpointing
  checkpoint:
    save_dir: "checkpoints"
    save_every_n_epochs: 5
    save_best_only: true
    monitor: "val_loss"  # Metric to monitor
    mode: "min"  # "min" or "max"

  # Logging
  logging:
    log_dir: "logs"
    log_every_n_steps: 10
    use_tensorboard: true
    save_audio_samples: true
    num_audio_samples: 5

  # Validation
  validation:
    val_every_n_epochs: 1
    val_split: 0.1  # Fraction of training data for validation
